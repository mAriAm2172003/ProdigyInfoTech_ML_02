# -*- coding: utf-8 -*-
"""Task2_ML_ProdigyInfoTech.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kE5xT1QHXkBvj1-tKWgiyCnApQ5V7vt1

**Import Libraries**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score
import seaborn as sns

"""**Load Dataset**"""

data = pd.read_csv('Mall_Customers.csv')

print(data.head())

data.info()

data.isnull().sum()

data.duplicated().sum()

"""**Data Visualization**"""

# Pairplot to visualize relationships between numerical features, grouped by gender
sns.pairplot(data, hue='Gender', palette='Set1')
plt.suptitle('Pairplot of Numerical Features, Grouped by Gender', y=1.02)
plt.show()

# Boxplot of Age by Gender
plt.figure(figsize=(10, 6))
sns.boxplot(x='Gender', y='Age', data=data, palette='Set1')
plt.title('Boxplot of Age by Gender')
plt.xlabel('Gender')
plt.ylabel('Age')
plt.show()

# Boxplot of Annual Income by Gender
plt.figure(figsize=(10, 6))
sns.boxplot(x='Gender', y='Annual Income (k$)', data=data, palette='Set1')
plt.title('Boxplot of Annual Income by Gender')
plt.xlabel('Gender')
plt.ylabel('Annual Income (k$)')
plt.show()

# Boxplot of Spending Score by Gender
plt.figure(figsize=(10, 6))
sns.boxplot(x='Gender', y='Spending Score (1-100)', data=data, palette='Set1')
plt.title('Boxplot of Spending Score by Gender')
plt.xlabel('Gender')
plt.ylabel('Spending Score (1-100)')
plt.show()

"""**Feature Selection**"""

# Drop unnecessary columns (CustomerID is not needed for clustering)
data.drop(['CustomerID', 'Age'], axis=1, inplace=True)

# Data Preprocessing
# Encode Gender column (1 for Male, 0 for Female)
data['Gender'] = data['Gender'].map({'Male': 1, 'Female': 0})
data.drop('Gender', axis=1, inplace=True)

# Feature Selection
# We'll use 'Annual Income (k$)', and 'Spending Score (1-100)' as our features for clustering
features = [ 'Annual Income (k$)', 'Spending Score (1-100)']
X = data[features]
X

# Standardize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

"""**Apply Elbow Method to determine the optimal number of clusters**"""

# Elbow Method to determine the optimal number of clusters
wcss = []  # Within Cluster Sum of Squares
for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, random_state=42)
    kmeans.fit(X_scaled)
    wcss.append(kmeans.inertia_)

# Plot the Elbow Method graph
plt.plot(range(1, 11), wcss, marker='o')
plt.title('Elbow Method')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Within Cluster Sum of Squares (WCSS)')
plt.xticks(range(1, 11))
plt.grid(True)
plt.show()

"""**Apply K-means clustering algorithm**"""

# Choose the optimal number of clusters based on the elbow method (let's say k=5)
optimal_k = 5

# Apply K-means clustering algorithm with the optimal number of clusters
kmeans = KMeans(n_clusters=optimal_k, random_state=42)
cluster_labels = kmeans.fit_predict(X_scaled)

# Add cluster labels to the original dataset
data['Cluster'] = cluster_labels
data

"""**Visualize the clusters in 2D & 3D**"""

# Visualize the clusters in 2D with centroids placed at the mean of each cluster
plt.figure(figsize=(10, 6))

colors = ['red', 'blue', 'green', 'purple', 'orange']
for cluster in range(5):
    cluster_data = data[data['Cluster'] == cluster]
    plt.scatter(cluster_data['Annual Income (k$)'], cluster_data['Spending Score (1-100)'],
                label=f'Cluster {cluster}', alpha=0.7, color=colors[cluster])

# Plot centroids at the mean of each cluster
for cluster in range(5):
    centroid = cluster_means.loc[cluster, ['Annual Income (k$)', 'Spending Score (1-100)']]
    plt.scatter(centroid[0], centroid[1], marker='x', s=200, c='black')

plt.xlabel('Annual Income (k$)')
plt.ylabel('Spending Score (1-100)')
plt.title('Clusters in 2D with Centroids at Mean of Each Cluster')
# Legend for data points only
plt.legend(['Cluster 0', 'Cluster 1', 'Cluster 2', 'Cluster 3', 'Cluster 4', 'Centroids'], loc='upper right')
plt.grid(True)
plt.show()

# Visualize the clusters in 3D with centroids placed at the mean of each cluster
fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')

colors = ['red', 'blue', 'green', 'purple', 'orange']
for cluster in range(5):
    cluster_data = data[data['Cluster'] == cluster]
    ax.scatter(cluster_data['Annual Income (k$)'], cluster_data['Spending Score (1-100)'],
               label=f'Cluster {cluster}', alpha=0.7, color=colors[cluster])

# Plot centroids at the mean of each cluster
for cluster in range(5):
    centroid = cluster_means.loc[cluster, ['Annual Income (k$)', 'Spending Score (1-100)']]
    ax.scatter(centroid[0], centroid[1], marker='x', s=200, c='black')

ax.set_xlabel('Annual Income (k$)')
ax.set_ylabel('Spending Score (1-100)')
ax.set_zlabel('Frequency')
ax.set_title('Clusters in 3D with Centroids at Mean of Each Cluster')
# Legend for data points only
ax.legend(['Cluster 0', 'Cluster 1', 'Cluster 2', 'Cluster 3', 'Cluster 4', 'Centroids'], loc='upper left')
plt.grid(True)
plt.show()